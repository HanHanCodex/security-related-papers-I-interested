# Rethinking the capability of fine-tuned language models for automated vulnerability repair

**研究方向：** LLM Security, Vulnerability Repair

## 📝 原文摘要 (Original Abstract)
> The success of large language models (LLMs) in code generation has fueled research into automated vulnerability repair (AVR). We leverage the Fusion-in-Decoder (FiD) framework to effectively process long and complex vulnerable code, surpassing typical model limitations. To enhance the ability to repair, VulMaster integrates Abstract Syntax Trees (ASTs) to preserve the semantic structure of code, incorporates CWE knowledge, and utilizes vulnerability-fix examples for both the same and related CWE-IDs.

## 💡 助理总结 (创新点/Insights)
> **重新思考微调后的语言模型在自动化漏洞修复中的能力和局限性。**
